{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deepfashion2 6 Categories.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DhKC90N37NC",
        "colab_type": "text"
      },
      "source": [
        "# **TESTING FOR deepfashion2**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfjCr0ns79dP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6FgC2ws79_c",
        "colab_type": "text"
      },
      "source": [
        "config.py\n",
        "\n",
        "MAX_GT_INSTANCES = 10\n",
        "\n",
        "DETECTION_MAX_INSTANCES = 5\n",
        "\n",
        "clothes.py\n",
        "\n",
        "STEPS_PER_EPOCH = 100\n",
        "DETECTION_MIN_CONFIDENCE = 0.9\n",
        "epochs=100\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y35NHQIrPQ8R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd21e887-3a96-4465-e7bb-adbc7945da24"
      },
      "source": [
        "#I added this\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dla8hlyXc2A2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "330a3be0-b902-47c3-c876-778407037397"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6RkEj__yVr-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5d0c3d0-55c5-4f03-f180-76280c99ff92"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPJ60RlQcBtt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a78675d-67dc-4263-d2bf-3b80e2c2b0f4"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kkk7V7TQhBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Here in this case, we are loading the data from the drive. So we don't have to clone the git repository\n",
        "#%cd\n",
        "#!git clone https://github.com/Bidish29/Mask-RCNN.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpjRJeTPQhVE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "efc51633-3ca9-4261-8aaa-305c18bbdc88"
      },
      "source": [
        "%cd /root"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVWqjg28cZ37",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c4a6765-1857-4627-c922-411d0a14860b"
      },
      "source": [
        "# HERE YOUR FILE ID ( GET IT WITH THE SHARING URL: https://drive.google.com/open?id=1Soh3zXLXt2lT7b_3FcWWyeOCC )\n",
        "#Deepfashion2_6_categories\n",
        "fileId = '1tbsqR39L_I_yX-tBGG_283vVfeXigipl'\n",
        "\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "from shutil import copy\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fileName = fileId + '.zip'\n",
        "downloaded = drive.CreateFile({'id': fileId})\n",
        "downloaded.GetContentFile(fileName)\n",
        "ds = ZipFile(fileName)\n",
        "ds.extractall()\n",
        "os.remove(fileName)\n",
        "print('Extracted zip file ' + fileName)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracted zip file 1tbsqR39L_I_yX-tBGG_283vVfeXigipl.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E5cpsz8coQr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7dba497-54b8-4bb6-e61a-fb064737541a"
      },
      "source": [
        "%cd /root/Deepfashion2_6_categories/dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/Deepfashion2_6_categories/dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYSp8oMac5iX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0eb771a1-6b60-4e26-c8b2-2441f36a9464"
      },
      "source": [
        "#Checks the number of items in the directory\n",
        "!ls /root/Deepfashion2_6_categories/dataset/train | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9pOdAzATmKo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bcdb9249-bf84-4a85-d837-8dd6fdde4f8e"
      },
      "source": [
        "#train_1\n",
        "fileId = '11q9GtuCIU4-L9zv3LxgJj4H6CCM6l9Db'\n",
        "\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "from shutil import copy\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fileName = fileId + '.zip'\n",
        "downloaded = drive.CreateFile({'id': fileId})\n",
        "downloaded.GetContentFile(fileName)\n",
        "ds = ZipFile(fileName)\n",
        "ds.extractall()\n",
        "os.remove(fileName)\n",
        "print('Extracted zip file ' + fileName)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracted zip file 11q9GtuCIU4-L9zv3LxgJj4H6CCM6l9Db.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "727gBpn2U-pU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this will move the contents of the folders. Once that is done then remove the train_*s folder\n",
        "!find /root/Deepfashion2_6_categories/dataset/train_1 -mindepth 1 -maxdepth 1 -name '*' -exec mv {} /root/Deepfashion2_6_categories/dataset/train \\;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1D-9GSjhKwR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bcb45a22-7cba-44ae-cdf2-d5d988b8d14f"
      },
      "source": [
        "#Checks the number of items in the directory\n",
        "!ls /root/Deepfashion2_6_categories/dataset/train | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhIC_o_zXE4l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0fb97e19-0402-4dd9-d909-8b37067bd5fe"
      },
      "source": [
        "#train_2\n",
        "fileId = '1TgGeZ0qJW0-ZUDpfFm-R-iOegDmssq84'\n",
        "\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "from shutil import copy\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fileName = fileId + '.zip'\n",
        "downloaded = drive.CreateFile({'id': fileId})\n",
        "downloaded.GetContentFile(fileName)\n",
        "ds = ZipFile(fileName)\n",
        "ds.extractall()\n",
        "os.remove(fileName)\n",
        "print('Extracted zip file ' + fileName)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracted zip file 1TgGeZ0qJW0-ZUDpfFm-R-iOegDmssq84.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC1ssBX0iRJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this will move the contents of the folders. Once that is done then remove the train_*s folder\n",
        "!find /root/Deepfashion2_6_categories/dataset/train_2 -mindepth 1 -maxdepth 1 -name '*' -exec mv {} /root/Deepfashion2_6_categories/dataset/train \\;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj2hFmQyiRXv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e2df994-cceb-4877-beb5-08171f265875"
      },
      "source": [
        "#Checks the number of items in the directory\n",
        "!ls /root/Deepfashion2_6_categories/dataset/train | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKcCQii7TmEV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a712203-9e30-4e0b-b341-47a1727a74a7"
      },
      "source": [
        "#train_3\n",
        "fileId = '1QZETNWjeaC9OCqVLXne-7dVveciNJ8uq'\n",
        "\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "from shutil import copy\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fileName = fileId + '.zip'\n",
        "downloaded = drive.CreateFile({'id': fileId})\n",
        "downloaded.GetContentFile(fileName)\n",
        "ds = ZipFile(fileName)\n",
        "ds.extractall()\n",
        "os.remove(fileName)\n",
        "print('Extracted zip file ' + fileName)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracted zip file 1QZETNWjeaC9OCqVLXne-7dVveciNJ8uq.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpY4W9wNTmA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this will move the contents of the folders. Once that is done then remove the train_*s folder\n",
        "!find /root/Deepfashion2_6_categories/dataset/train_3 -mindepth 1 -maxdepth 1 -name '*' -exec mv {} /root/Deepfashion2_6_categories/dataset/train \\;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szhg3pYUjv9N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ac1d4d00-52d6-43df-db7a-e4604dd45b9a"
      },
      "source": [
        "#Checks the number of items in the directory\n",
        "!ls /root/Deepfashion2_6_categories/dataset/train | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "150001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg2SGGFRjv5D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a616fb87-a1cb-4855-e7c4-e659bf0e482b"
      },
      "source": [
        "#train_4\n",
        "fileId = '1E7ecvERomdrdBxZK3W8caDLXlnClN6jf'\n",
        "\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "from shutil import copy\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fileName = fileId + '.zip'\n",
        "downloaded = drive.CreateFile({'id': fileId})\n",
        "downloaded.GetContentFile(fileName)\n",
        "ds = ZipFile(fileName)\n",
        "ds.extractall()\n",
        "os.remove(fileName)\n",
        "print('Extracted zip file ' + fileName)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracted zip file 1E7ecvERomdrdBxZK3W8caDLXlnClN6jf.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRd0ZKC6jv07",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this will move the contents of the folders. Once that is done then remove the train_*s folder\n",
        "!find /root/Deepfashion2_6_categories/dataset/train_4 -mindepth 1 -maxdepth 1 -name '*' -exec mv {} /root/Deepfashion2_6_categories/dataset/train \\;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDl1oGQYlGCs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd0fab9c-ff82-4345-e3ff-b7362b8b6b16"
      },
      "source": [
        "#Checks the number of items in the directory\n",
        "!ls /root/Deepfashion2_6_categories/dataset/train | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "191962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6Pj5LYGTl9N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d958bba-63c7-467e-f030-6b7d11c8d2fb"
      },
      "source": [
        "#Checks the number of items in the directory\n",
        "!ls /root/Deepfashion2_6_categories/dataset/val | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYDR2naisGuy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db6c6c40-5edd-4c7c-c90a-ba44fbdc5241"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/Deepfashion2_6_categories/dataset'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEGVuNiAQhYc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aefe2bd6-bd76-41e9-e114-d8e70715a974"
      },
      "source": [
        "%cd /root/Deepfashion2_6_categories/Mask_RCNN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/Deepfashion2_6_categories/Mask_RCNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8wMLnGAPRxD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a69e4658-1965-42a5-b093-b0d1aa18b1b9"
      },
      "source": [
        "\n",
        "!pip install -q PyDrive\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py install"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (7.0.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (0.29.20)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.16.2)\n",
            "Requirement already satisfied: tensorflow>=1.3.0 in /tensorflow-1.15.2/python3.6 (from -r requirements.txt (line 7)) (1.15.2)\n",
            "Requirement already satisfied: keras>=2.0.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (2.3.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (4.1.2.30)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (2.10.0)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (0.2.9)\n",
            "Requirement already satisfied: IPython[all] in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 12)) (5.5.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.4.7)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 6)) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.4)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.34.2)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /tensorflow-1.15.2/python3.6 (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.15.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.29.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.2.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.0.8)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /tensorflow-1.15.2/python3.6 (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.8->-r requirements.txt (line 8)) (3.13)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug->-r requirements.txt (line 11)) (1.7.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (47.3.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (1.0.18)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.3.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (2.1.3)\n",
            "Requirement already satisfied: nbconvert; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.6.1)\n",
            "Requirement already satisfied: Sphinx>=1.3; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (1.8.5)\n",
            "Requirement already satisfied: requests; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (2.23.0)\n",
            "Requirement already satisfied: qtconsole; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.7.4)\n",
            "Requirement already satisfied: nbformat; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.0.7)\n",
            "Requirement already satisfied: ipyparallel; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (6.3.0)\n",
            "Requirement already satisfied: testpath; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.4.4)\n",
            "Requirement already satisfied: nose>=0.10.1; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (1.3.7)\n",
            "Requirement already satisfied: ipywidgets; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (7.5.1)\n",
            "Requirement already satisfied: ipykernel; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.10.1)\n",
            "Requirement already satisfied: notebook; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.0.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython[all]->-r requirements.txt (line 12)) (0.2.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->IPython[all]->-r requirements.txt (line 12)) (0.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->IPython[all]->-r requirements.txt (line 12)) (0.2.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.4.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.8.4)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.11.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (3.1.5)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (4.6.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (20.4)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.2.2)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.8.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.2.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.7.12)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.15.2)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2020.4.5.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.9)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.9.0)\n",
            "Requirement already satisfied: jupyter-client>=4.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (5.3.4)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (19.0.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.6.0)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from ipyparallel; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (4.5.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (3.5.1)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.8.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.1.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.5.1)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.6/dist-packages (from babel!=2.0,>=1.3->Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2018.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.1.0)\n",
            "WARNING:root:Fail load requirements file, so using default ones.\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing mask_rcnn.egg-info/PKG-INFO\n",
            "writing dependency_links to mask_rcnn.egg-info/dependency_links.txt\n",
            "writing top-level names to mask_rcnn.egg-info/top_level.txt\n",
            "reading manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/config.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/visualize.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/__init__.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/parallel_model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/utils.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/config.py to config.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/visualize.py to visualize.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/model.py to model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/parallel_model.py to parallel_model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/utils.py to utils.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating 'dist/mask_rcnn-2.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing mask_rcnn-2.1-py3.6.egg\n",
            "Removing /usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg\n",
            "Copying mask_rcnn-2.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "mask-rcnn 2.1 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg\n",
            "Processing dependencies for mask-rcnn==2.1\n",
            "Finished processing dependencies for mask-rcnn==2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO2l3IlRDovI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c8ca7d7-b636-481b-f8b8-d2dfca88c738"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/Deepfashion2_6_categories/Mask_RCNN'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwrWhNp6F2CC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "e89edebc-97c3-4c5d-9d53-ed051f4895c9"
      },
      "source": [
        "weights =model.find_last()\n",
        "print(\"Loading weights \", weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-7d88941a2039>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_last\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading weights \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gf8LCnCW9ZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGEoF9HwF4RT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64159855-3385-49fa-d1a3-fb944fc84df2"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/Deepfashion2/Mask_RCNN'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YdTo5vOQyoO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bdce1626-0169-43d3-d2f1-a7f92ec338b8"
      },
      "source": [
        "!python clothes.py train --dataset=/root/Deepfashion2_6_categories/dataset --weights=mask_rcnn_object_0100.h5\n",
        "#!python clothes.py train --dataset=/root/main7/dataset --weights=/root/logs/object20200609T1609/mask_rcnn_object_0030.h5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "Weights:  mask_rcnn_object_0100.h5\n",
            "Dataset:  /root/Deepfashion2_6_categories/dataset\n",
            "Logs:  /root/logs\n",
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     2\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        5\n",
            "DETECTION_MIN_CONFIDENCE       0.9\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 2\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                19\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               10\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           object\n",
            "NUM_CLASSES                    7\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                100\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /root/Deepfashion2_6_categories/Mask_RCNN/mrcnn/model.py:553: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
            "\n",
            "WARNING:tensorflow:From /root/Deepfashion2_6_categories/Mask_RCNN/mrcnn/utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /root/Deepfashion2_6_categories/Mask_RCNN/mrcnn/model.py:600: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "Loading weights  mask_rcnn_object_0100.h5\n",
            "2020-06-23 12:05:00.878180: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-06-23 12:05:00.881815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-23 12:05:00.882553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-06-23 12:05:00.882970: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-23 12:05:00.885126: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-06-23 12:05:00.886980: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-06-23 12:05:00.887363: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-06-23 12:05:00.892420: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-06-23 12:05:00.894047: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-06-23 12:05:00.898369: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-06-23 12:05:00.898553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-23 12:05:00.899340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-23 12:05:00.900057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-06-23 12:05:00.919016: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-06-23 12:05:00.919257: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1a6a0bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-06-23 12:05:00.919294: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-06-23 12:05:00.967822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-23 12:05:00.968612: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1a6a0d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-06-23 12:05:00.968663: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-06-23 12:05:00.968951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-23 12:05:00.969725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-06-23 12:05:00.969809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-23 12:05:00.969886: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-06-23 12:05:00.969933: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-06-23 12:05:00.969991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-06-23 12:05:00.970056: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-06-23 12:05:00.970098: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-06-23 12:05:00.970138: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-06-23 12:05:00.970312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-23 12:05:00.971189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-23 12:05:00.971910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-06-23 12:05:00.971981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-23 12:05:00.973619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-06-23 12:05:00.973666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-06-23 12:05:00.973695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-06-23 12:05:00.973862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-23 12:05:00.974674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-23 12:05:00.975421: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-06-23 12:05:00.975473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10747 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['short sleeve top', 'short sleeve top']\n",
            "numids [1, 1]\n",
            "objects: ['dress']\n",
            "numids [3]\n",
            "objects: ['dress']\n",
            "numids [3]\n",
            "objects: ['dress']\n",
            "numids [3]\n",
            "objects: ['dress']\n",
            "numids [3]\n",
            "objects: ['dress']\n",
            "numids [3]\n",
            "objects: ['dress']\n",
            "numids [3]\n",
            "objects: ['long sleeve top']\n",
            "numids [2]\n",
            "objects: ['long sleeve top']\n",
            "numids [2]\n",
            "objects: ['trousers', 'long sleeve top']\n",
            "numids [6, 2]\n",
            "objects: ['trousers', 'long sleeve top']\n",
            "numids [6, 2]\n",
            "objects: ['skirt', 'long sleeve top']\n",
            "numids [4, 2]\n",
            "objects: ['skirt', 'long sleeve top']\n",
            "numids [4, 2]\n",
            "objects: ['long sleeve top']\n",
            "numids [2]\n",
            "objects: ['trousers', 'long sleeve top']\n",
            "numids [6, 2]\n",
            "objects: ['trousers', 'long sleeve top']\n",
            "numids [6, 2]\n",
            "objects: ['trousers', 'long sleeve top']\n",
            "numids [6, 2]\n",
            "objects: ['skirt', 'long sleeve top']\n",
            "numids [4, 2]\n",
            "objects: ['long sleeve top']\n",
            "numids [2]\n",
            "objects: ['skirt', 'short sleeve top']\n",
            "numids [4, 1]\n",
            "objects: ['skirt', 'short sleeve top']\n",
            "numids [4, 1]\n",
            "objects: ['skirt', 'short sleeve top']\n",
            "numids [4, 1]\n",
            "objects: ['short sleeve top', 'skirt']\n",
            "numids [1, 4]\n",
            "objects: ['short sleeve top', 'skirt']\n",
            "numids [1, 4]\n",
            "objects: ['skirt', 'short sleeve top']\n",
            "numids [4, 1]\n",
            "objects: ['skirt', 'short sleeve top']\n",
            "numids [4, 1]\n",
            "objects: ['short sleeve top', 'skirt']\n",
            "numids [1, 4]\n",
            "objects: ['skirt', 'short sleeve top']\n",
            "numids [4, 1]\n",
            "objects: ['short sleeve top', 'skirt']\n",
            "numids [1, 4]\n",
            "objects: ['skirt', 'short sleeve top']\n",
            "numids [4, 1]\n",
            "objects: ['skirt', 'short sleeve top']\n",
            "numids [4, 1]\n",
            "objects: ['shorts']\n",
            "numids [5]\n",
            "objects: ['short sleeve top', 'shorts']\n",
            "numids [1, 5]\n",
            "objects: ['short sleeve top', 'shorts']\n",
            "numids [1, 5]\n",
            "objects: ['short sleeve top', 'shorts']\n",
            "numids [1, 5]\n",
            "objects: ['shorts']\n",
            "numids [5]\n",
            "objects: ['shorts']\n",
            "numids [5]\n",
            "objects: ['shorts', 'short sleeve top']\n",
            "numids [5, 1]\n",
            "objects: ['shorts', 'short sleeve top']\n",
            "numids [5, 1]\n",
            "objects: ['short sleeve top', 'shorts']\n",
            "numids [1, 5]\n",
            "objects: ['shorts', 'short sleeve top']\n",
            "numids [5, 1]\n",
            "objects: ['shorts', 'short sleeve top']\n",
            "numids [5, 1]\n",
            "objects: ['short sleeve top', 'shorts']\n",
            "numids [1, 5]\n",
            "objects: ['short sleeve top', 'shorts']\n",
            "numids [1, 5]\n",
            "objects: ['short sleeve top', 'shorts']\n",
            "numids [1, 5]\n",
            "objects: ['shorts', 'short sleeve top']\n",
            "numids [5, 1]\n",
            "objects: ['short sleeve top', 'shorts']\n",
            "numids [1, 5]\n",
            "objects: ['shorts', 'short sleeve top']\n",
            "numids [5, 1]\n",
            "objects: ['short sleeve top', 'shorts']\n",
            "numids [1, 5]\n",
            "objects: ['shorts', 'short sleeve top']\n",
            "numids [5, 1]\n",
            "objects: ['shorts', 'short sleeve top']\n",
            "numids [5, 1]\n",
            "objects: ['shorts', 'short sleeve top']\n",
            "numids [5, 1]\n",
            "objects: ['shorts', 'short sleeve top']\n",
            "numids [5, 1]\n",
            "objects: ['shorts', 'short sleeve top']\n",
            "numids [5, 1]\n",
            "objects: ['short sleeve top', 'shorts']\n",
            "numids [1, 5]\n",
            "objects: ['shorts', 'short sleeve top']\n",
            "numids [5, 1]\n",
            "objects: ['short sleeve top', 'shorts']\n",
            "numids [1, 5]\n",
            "objects: ['short sleeve top', 'shorts']\n",
            "numids [1, 5]\n",
            "objects: ['shorts', 'short sleeve top']\n",
            "numids [5, 1]\n",
            "objects: ['short sleeve top', 'shorts']\n",
            "numids [1, 5]\n",
            "objects: ['short sleeve top', 'shorts']\n",
            "numids [1, 5]\n",
            "objects: ['skirt', 'short sleeve top']\n",
            "numids [4, 1]\n",
            "objects: ['skirt', 'short sleeve top']\n",
            "numids [4, 1]\n",
            "objects: ['short sleeve top']\n",
            "numids [1]\n",
            "objects: ['skirt', 'short sleeve top']\n",
            "numids [4, 1]\n",
            "objects: ['shorts', 'short sleeve top']\n",
            "numids [5, 1]\n",
            "objects: ['skirt', 'short sleeve top']\n",
            "numids [4, 1]\n",
            "objects: ['shorts', 'short sleeve top']\n",
            "numids [5, 1]\n",
            "objects: ['skirt', 'short sleeve top']\n",
            "numids [4, 1]\n",
            "objects: ['short sleeve top']\n",
            "numids [1]\n",
            "objects: ['short sleeve top']\n",
            "numids [1]\n",
            "objects: ['short sleeve top', 'trousers']\n",
            "numids [1, 6]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['short sleeve top', 'trousers']\n",
            "numids [1, 6]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['short sleeve top', 'trousers']\n",
            "numids [1, 6]\n",
            "objects: ['short sleeve top', 'trousers']\n",
            "numids [1, 6]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['long sleeve top']\n",
            "numids [2]\n",
            "objects: ['long sleeve top']\n",
            "numids [2]\n",
            "objects: ['long sleeve top']\n",
            "numids [2]\n",
            "objects: ['trousers', 'long sleeve top']\n",
            "numids [6, 2]\n",
            "objects: ['trousers', 'long sleeve top']\n",
            "numids [6, 2]\n",
            "objects: ['long sleeve top']\n",
            "numids [2]\n",
            "objects: ['trousers', 'long sleeve top']\n",
            "numids [6, 2]\n",
            "objects: ['long sleeve top']\n",
            "numids [2]\n",
            "objects: ['trousers', 'long sleeve top']\n",
            "numids [6, 2]\n",
            "objects: ['trousers', 'long sleeve top']\n",
            "numids [6, 2]\n",
            "objects: ['trousers', 'long sleeve top']\n",
            "numids [6, 2]\n",
            "objects: ['trousers', 'long sleeve top']\n",
            "numids [6, 2]\n",
            "objects: ['long sleeve top']\n",
            "numids [2]\n",
            "objects: ['long sleeve top']\n",
            "numids [2]\n",
            "objects: ['trousers', 'long sleeve top']\n",
            "numids [6, 2]\n",
            "objects: ['long sleeve top']\n",
            "numids [2]\n",
            "objects: ['trousers', 'long sleeve top']\n",
            "numids [6, 2]\n",
            "objects: ['short sleeve top']\n",
            "numids [1]\n",
            "objects: ['shorts', 'short sleeve top']\n",
            "numids [5, 1]\n",
            "objects: ['short sleeve top']\n",
            "numids [1]\n",
            "objects: ['short sleeve top']\n",
            "numids [1]\n",
            "objects: ['short sleeve top']\n",
            "numids [1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['short sleeve top']\n",
            "numids [1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['short sleeve top', 'trousers']\n",
            "numids [1, 6]\n",
            "objects: ['long sleeve top', 'trousers']\n",
            "numids [2, 6]\n",
            "objects: ['long sleeve top', 'trousers']\n",
            "numids [2, 6]\n",
            "objects: ['long sleeve top', 'trousers']\n",
            "numids [2, 6]\n",
            "objects: ['long sleeve top', 'trousers']\n",
            "numids [2, 6]\n",
            "objects: ['long sleeve top', 'trousers']\n",
            "numids [2, 6]\n",
            "objects: ['long sleeve top', 'trousers']\n",
            "numids [2, 6]\n",
            "objects: ['long sleeve top', 'trousers']\n",
            "numids [2, 6]\n",
            "objects: ['long sleeve top', 'trousers']\n",
            "numids [2, 6]\n",
            "objects: ['long sleeve top', 'trousers']\n",
            "numids [2, 6]\n",
            "objects: ['long sleeve top', 'trousers']\n",
            "numids [2, 6]\n",
            "objects: ['long sleeve top', 'trousers']\n",
            "numids [2, 6]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['trousers', 'short sleeve top']\n",
            "numids [6, 1]\n",
            "objects: ['dress']\n",
            "numids [3]\n",
            "objects: ['dress']\n",
            "numids [3]\n",
            "objects: ['dress']\n",
            "numids [3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxLY4WRdSbeo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "4d47d701-831b-4795-c35c-5f612360a072"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/Deepfashion2_6_categories/Mask_RCNN'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2--ChN2QzAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}