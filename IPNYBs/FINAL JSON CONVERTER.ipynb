{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to extract 10000 Random images\n",
    "import os, random\n",
    "import shutil\n",
    "\n",
    "m = 5000\n",
    "\n",
    "#Validation Source folder\n",
    "src_dir = \"D:/DCU/Practicum/Datasets/DeepFashion2/validation/image/\"\n",
    "\n",
    "# Use this to copy files to  the validation folder\n",
    "dst_dir = \"D:/DCU/Practicum/Datasets/DeepFashion2/Mask RCNN/Clothes/Dataset_generator/dataset/val\"\n",
    "\n",
    "# Use this to copy files to  the training folder\n",
    "#dst_dir = \"D:/DCU/Practicum/Datasets/DeepFashion2/Mask RCNN/Clothes/Dataset_generator/dataset/train\"\n",
    "\n",
    "file_list = os.listdir(src_dir)\n",
    "\n",
    "for i in range(m):\n",
    "        a = random.choice(file_list)\n",
    "        shutil.copy(src_dir + a, dst_dir + \"/\" + a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4645\n"
     ]
    }
   ],
   "source": [
    "from os.path import splitext\n",
    "import shutil\n",
    "import os, random\n",
    "\n",
    "#Source is training folder\n",
    "#src = \"D:/DCU/Practicum/Datasets/DeepFashion2/Mask RCNN/Clothes/Dataset_generator/dataset/train\"\n",
    "\n",
    "#Source is validation folder\n",
    "src = \"D:/DCU/Practicum/Datasets/DeepFashion2/Mask RCNN/Clothes/Dataset_generator/dataset/val\"\n",
    "\n",
    "#Validation annotation source\n",
    "anno = 'D:/DCU/Practicum/Datasets/DeepFashion2/validation/annos/'\n",
    "\n",
    "#Training destination\n",
    "#dst_dir = \"D:/DCU/Practicum/Datasets/DeepFashion2/Mask RCNN/Clothes/Dataset_generator/dataset/train/annotations\"\n",
    "\n",
    "#Validation destination\n",
    "dst_dir = \"D:/DCU/Practicum/Datasets/DeepFashion2/Mask RCNN/Clothes/Dataset_generator/dataset/val/annotations\"\n",
    "list2 = os.listdir(src)\n",
    "list1 = os.listdir(anno)\n",
    "\n",
    "documents = set([splitext(filename)[0] for filename in list2])\n",
    "matches = [filename for filename in set(list1) if splitext(filename)[0] in documents]\n",
    "\n",
    "#print (matches)\n",
    "#print(type(matches))\n",
    "print (len(matches))\n",
    "m = len(matches)\n",
    "#file_list = os.listdir(matches)\n",
    "\n",
    "for i in range(m):\n",
    "        a = matches[i]\n",
    "        shutil.copy(anno + a, dst_dir + \"/\" + a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#src=\"D:/DCU/Practicum/Datasets/DeepFashion2/JSON_EDIT/New/037535.json\" #Source file location with the file name\n",
    "#src1=src[-11:]#Select the last 11 characters\n",
    "#sep = '.'\n",
    "#filename = src1.split(sep, 1)[0]\n",
    "#filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the .json file and take only the category name and the segmentation values.\n",
    "#import pandas as pd\n",
    "#import os\n",
    "#import json\n",
    "#df1=pd.read_json(src)\n",
    "#df1 = df1.loc[ ['category_name','segmentation'],:]\n",
    "#Filter out all the unwanted columns and keep only those columns which have the necessary clothing item segment values and the \n",
    "#category names.\n",
    "#df=df1.filter(like='item')\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n=len(df.columns) # count the number of columns and based on it there will be that many classes in each json file of every image.\n",
    "#print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #def Convert(string): \n",
    "# #    li = list(string.split(\",\")) \n",
    "# #    return li \n",
    "\n",
    "# #if n==1:\n",
    "#     cat_name_1=df.iloc[0].iloc[0] #1st category\n",
    "#     #print(\"Category1:\",cat_name_1)\n",
    "#     a1=df.iloc[1]\n",
    "#     b1=a1.iloc[0]\n",
    "#     c1=str(b1).replace(\"[\", \"\")#strip('[]')\n",
    "#     d1=c1.replace(\"]\", \"\")\n",
    "#     e1=Convert(d1)\n",
    "#     e1 = [round(float(x)) for x in e1]\n",
    "#     x1= e1[::2] #numbers in even position\n",
    "#     y1= e1[1::2] #numbers in odd position\n",
    "#     base=filename+'.jpg'\n",
    "#     dict1 = {base: {'filename': base,'regions': [{'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x1)),\n",
    "#                                          'all_points_y': list(map(int, y1))},'region_attributes': {'name': cat_name_1}}]}}\n",
    "#     with open(filename+'_new.json', 'w') as fp:\n",
    "#         json.dump(dict1, fp)\n",
    "\n",
    "\n",
    "# elif n==2:\n",
    "#     cat_name_1=df.iloc[0].iloc[0]#1st category\n",
    "#     cat_name_2=df.iloc[0].iloc[1]#2nd category\n",
    "#     #print(\"Category1:\",cat_name_1,\"\\nCategory2:\",cat_name_2)\n",
    "#     a=df.iloc[1]\n",
    "\n",
    "#     b1=a.iloc[0]\n",
    "#     b2=a.iloc[1]\n",
    "\n",
    "#     c1=str(b1).replace(\"[\", \"\")#strip('[]')\n",
    "#     d1=c1.replace(\"]\", \"\")\n",
    "#     c2=str(b2).replace(\"[\", \"\")#strip('[]')\n",
    "#     d2=c2.replace(\"]\", \"\")\n",
    "\n",
    "#     e1=Convert(d1)\n",
    "#     e2=Convert(d2)\n",
    "\n",
    "#     x1= e1[::2]\n",
    "#     y1= e1[1::2] \n",
    "#     x2= e2[::2]\n",
    "#     y2= e2[1::2]\n",
    "\n",
    "#     base=filename+'.jpg'\n",
    "#     dict1 = {base: {'filename': base,'regions': [{'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x1)),\n",
    "#                                          'all_points_y': list(map(int, y1))},'region_attributes': {'name': cat_name_1}},\n",
    "#                                             {'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x2)),\n",
    "#                                          'all_points_y': list(map(int, y2))},'region_attributes': {'name': cat_name_2}}]}}\n",
    "\n",
    "#     with open(filename+'_new.json', 'w') as fp:\n",
    "#         json.dump(dict1, fp)\n",
    "\n",
    "# else:\n",
    "#     print(\"N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Recursively going through all the files\n",
    "# import glob\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# import json\n",
    "\n",
    "# def Convert(string): \n",
    "#     li = list(string.split(\",\")) \n",
    "#     return li\n",
    "\n",
    "# # Recursively print png images in folder C:\\Users\\admin\\\n",
    "# for filepath in glob.iglob(r'D:\\DCU\\Practicum\\Datasets\\DeepFashion2\\Mask RCNN\\Clothes\\main5\\dataset\\train\\annotations\\*.json', recursive=True):\n",
    "    \n",
    "#     src1=filepath[-11:]#Select the last 11 characters\n",
    "#     sep = '.'\n",
    "#     filename = src1.split(sep, 1)[0]\n",
    "#     #print(filename)\n",
    "    \n",
    "#     df1=pd.read_json(filepath)\n",
    "#     df1 = df1.loc[ ['category_name','segmentation'],:]\n",
    "#     #Filter out all the unwanted columns and keep only those columns which have the necessary clothing item segment values and the \n",
    "#     #category names.\n",
    "#     df=df1.filter(like='item')\n",
    "#     n=len(df.columns) \n",
    "#     if n==1:\n",
    "#         cat_name_1=df.iloc[0].iloc[0] #1st category\n",
    "#         #print(\"Category1:\",cat_name_1)\n",
    "#         a1=df.iloc[1]\n",
    "#         b1=a1.iloc[0]\n",
    "#         c1=str(b1).replace(\"[\", \"\")#strip('[]')\n",
    "#         d1=c1.replace(\"]\", \"\")\n",
    "#         e1=Convert(d1)\n",
    "#         e1 = \n",
    "#         x1= e1[::2] #numbers in even position\n",
    "#         y1= e1[1::2] #numbers in odd position\n",
    "#         base=filename+'.jpg'\n",
    "#         dict1 = {base: {'filename': base,'regions': [{'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x1)),\n",
    "#                                              'all_points_y': list(map(int, y1))},'region_attributes': {'name': cat_name_1}}]}}\n",
    "#         with open(filename+'_new.json', 'w') as fp:\n",
    "#             json.dump(dict1, fp)\n",
    "\n",
    "\n",
    "#     elif n==2:\n",
    "#         cat_name_1=df.iloc[0].iloc[0]#1st category\n",
    "#         cat_name_2=df.iloc[0].iloc[1]#2nd category\n",
    "#         #print(\"Category1:\",cat_name_1,\"\\nCategory2:\",cat_name_2)\n",
    "#         a=df.iloc[1]\n",
    "\n",
    "#         b1=a.iloc[0]\n",
    "#         b2=a.iloc[1]\n",
    "\n",
    "#         c1=str(b1).replace(\"[\", \"\")#strip('[]')\n",
    "#         d1=c1.replace(\"]\", \"\")\n",
    "#         c2=str(b2).replace(\"[\", \"\")#strip('[]')\n",
    "#         d2=c2.replace(\"]\", \"\")\n",
    "\n",
    "#         e1=Convert(d1)\n",
    "#         e2=Convert(d2)\n",
    "        \n",
    "#         e1 = [round(float(x)) for x in e1]\n",
    "#         e2 = [round(float(x)) for x in e2]\n",
    "\n",
    "#         x1= e1[::2]\n",
    "#         y1= e1[1::2] \n",
    "#         x2= e2[::2]\n",
    "#         y2= e2[1::2]\n",
    "\n",
    "#         base=filename+'.jpg'\n",
    "#         dict1 = {base: {'filename': base,'regions': [{'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x1)),\n",
    "#                                              'all_points_y': list(map(int, y1))},'region_attributes': {'name': cat_name_1}},\n",
    "#                                                 {'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x2)),\n",
    "#                                              'all_points_y': list(map(int, y2))},'region_attributes': {'name': cat_name_2}}]}}\n",
    "\n",
    "#         with open(filename+'_new.json', 'w') as fp:\n",
    "#             json.dump(dict1, fp)\n",
    "\n",
    "#     else:\n",
    "#         print(\"There are\",n,\"categories. Include more.\");\n",
    "#         break;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DCU\\Practicum\\Datasets\\DeepFashion2\\Mask RCNN\\Clothes\\Dataset_generator\\dataset\\train\\annotations\\new_annotations\n"
     ]
    }
   ],
   "source": [
    "# Run the code while in the destination folder. \n",
    "# switch between train and val as needed----------------------------------------------here\n",
    "%cd D:\\DCU\\Practicum\\Datasets\\DeepFashion2\\Mask RCNN\\Clothes\\Dataset_generator\\dataset\\train\\annotations\\new_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this next\n",
    "# Changing the way the dictionary is written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Recursively going through all the files\n",
    "# import glob\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# import json\n",
    "\n",
    "# def Convert(string): \n",
    "#     li = list(string.split(\",\")) \n",
    "#     return li\n",
    "\n",
    "# # switch between train and val as needed-----------------------------------------------------------------------here\n",
    "# for filepath in glob.iglob(r'D:\\DCU\\Practicum\\Datasets\\DeepFashion2\\Mask RCNN\\Clothes\\Dataset_generator\\dataset\\train\\annotations\\*.json', recursive=True):\n",
    "    \n",
    "#     src1=filepath[-11:]#Select the last 11 characters\n",
    "#     sep = '.'\n",
    "#     filename = src1.split(sep, 1)[0]\n",
    "#     #print(filename)\n",
    "    \n",
    "#     df1=pd.read_json(filepath)\n",
    "#     df1 = df1.loc[ ['category_name','segmentation'],:]\n",
    "#     #Filter out all the unwanted columns and keep only those columns which have the necessary clothing item segment values and the \n",
    "#     #category names.\n",
    "#     df=df1.filter(like='item')\n",
    "#     n=len(df.columns) \n",
    "#     if n==1:\n",
    "#         cat_name_1=df.iloc[0].iloc[0] #1st category\n",
    "#         #print(\"Category1:\",cat_name_1)\n",
    "#         a1=df.iloc[1]\n",
    "        \n",
    "#         b1=a1.iloc[0]\n",
    "        \n",
    "#         c1=str(b1).replace(\"[\", \"\")#strip('[]')\n",
    "        \n",
    "#         d1=c1.replace(\"]\", \"\")\n",
    "        \n",
    "#         e1=Convert(d1)\n",
    "#         e1=[float(i) for i in e1]\n",
    "#         e1=list(map(int,e1))\n",
    "        \n",
    "#         x1= e1[::2] #numbers in even position\n",
    "#         y1= e1[1::2] #numbers in odd position\n",
    "        \n",
    "#         base=filename+'.jpg'\n",
    "#         dict1 =  {'filename': base,'regions': [{'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x1)),\n",
    "#                                              'all_points_y': list(map(int, y1))},'region_attributes': {'name': cat_name_1}}]}\n",
    "#         with open(filename+'_new.json', 'w') as fp:\n",
    "#             json.dump(dict1, fp)\n",
    "\n",
    "\n",
    "#     elif n==2:\n",
    "#         cat_name_1=df.iloc[0].iloc[0]#1st category\n",
    "#         cat_name_2=df.iloc[0].iloc[1]#2nd category\n",
    "#         #print(\"Category1:\",cat_name_1,\"\\nCategory2:\",cat_name_2)\n",
    "#         a=df.iloc[1]\n",
    "\n",
    "#         b1=a.iloc[0]\n",
    "#         b2=a.iloc[1]\n",
    "\n",
    "#         c1=str(b1).replace(\"[\", \"\")#strip('[]')\n",
    "#         d1=c1.replace(\"]\", \"\")\n",
    "#         c2=str(b2).replace(\"[\", \"\")#strip('[]')\n",
    "#         d2=c2.replace(\"]\", \"\")\n",
    "\n",
    "#         e1=Convert(d1)\n",
    "#         e2=Convert(d2)\n",
    "        \n",
    "#         e1=[float(i) for i in e1]\n",
    "#         e1=list(map(int,e1))\n",
    "#         e2=[float(i) for i in e2]\n",
    "#         e2=list(map(int,e2))\n",
    "\n",
    "#         x1= e1[::2]\n",
    "#         y1= e1[1::2] \n",
    "#         x2= e2[::2]\n",
    "#         y2= e2[1::2]\n",
    "\n",
    "#         base=filename+'.jpg'\n",
    "#         dict1 = {'filename': base,'regions': [{'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x1)),\n",
    "#                                              'all_points_y': list(map(int, y1))},'region_attributes': {'name': cat_name_1}},\n",
    "#                                                 {'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x2)),\n",
    "#                                              'all_points_y': list(map(int, y2))},'region_attributes': {'name': cat_name_2}}]}\n",
    "\n",
    "#         with open(filename+'_new.json', 'w') as fp:\n",
    "#             json.dump(dict1, fp)\n",
    "            \n",
    "#     elif n==3:\n",
    "#         cat_name_1=df.iloc[0].iloc[0]#1st category\n",
    "#         cat_name_2=df.iloc[0].iloc[1]#2nd category\n",
    "#         cat_name_3=df.iloc[0].iloc[2]#3nd category\n",
    "#         #print(\"Category1:\",cat_name_1,\"\\nCategory2:\",cat_name_2)\n",
    "#         a=df.iloc[1]\n",
    "\n",
    "#         b1=a.iloc[0]\n",
    "#         b2=a.iloc[1]\n",
    "#         b3=a.iloc[2]\n",
    "\n",
    "#         c1=str(b1).replace(\"[\", \"\")#strip('[]')\n",
    "#         d1=c1.replace(\"]\", \"\")\n",
    "#         c2=str(b2).replace(\"[\", \"\")#strip('[]')\n",
    "#         d2=c2.replace(\"]\", \"\")\n",
    "#         c3=str(b3).replace(\"[\", \"\")#strip('[]')\n",
    "#         d3=c3.replace(\"]\", \"\")\n",
    "\n",
    "#         e1=Convert(d1)\n",
    "#         e2=Convert(d2)\n",
    "#         e3=Convert(d3)\n",
    "        \n",
    "#         e1=[float(i) for i in e1]\n",
    "#         e1=list(map(int,e1))\n",
    "#         e2=[float(i) for i in e2]\n",
    "#         e2=list(map(int,e2))\n",
    "#         e3=[float(i) for i in e3]\n",
    "#         e3=list(map(int,e3))\n",
    "\n",
    "#         x1= e1[::2]\n",
    "#         y1= e1[1::2] \n",
    "#         x2= e2[::2]\n",
    "#         y2= e2[1::2]\n",
    "#         x3= e3[::2]\n",
    "#         y3= e3[1::2]\n",
    "\n",
    "#         base=filename+'.jpg'\n",
    "#         dict1 = {'filename': base,'regions': [{'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x1)),\n",
    "#                                              'all_points_y': list(map(int, y1))},'region_attributes': {'name': cat_name_1}},\n",
    "                                                \n",
    "#                                               {'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x2)),\n",
    "#                                              'all_points_y': list(map(int, y2))},'region_attributes': {'name': cat_name_2}},\n",
    "                                             \n",
    "#                                               {'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x3)),\n",
    "#                                             'all_points_y': list(map(int, y3))},'region_attributes': {'name': cat_name_3}}]}\n",
    "\n",
    "#         with open(filename+'_new.json', 'w') as fp:\n",
    "#             json.dump(dict1, fp)\n",
    "            \n",
    "#     elif n==4:\n",
    "#         cat_name_1=df.iloc[0].iloc[0]#1st category\n",
    "#         cat_name_2=df.iloc[0].iloc[1]#2nd category\n",
    "#         cat_name_3=df.iloc[0].iloc[2]#3nd category\n",
    "#         cat_name_4=df.iloc[0].iloc[3]#3nd category\n",
    "#         #print(\"Category1:\",cat_name_1,\"\\nCategory2:\",cat_name_2)\n",
    "#         a=df.iloc[1]\n",
    "\n",
    "#         b1=a.iloc[0]\n",
    "#         b2=a.iloc[1]\n",
    "#         b3=a.iloc[2]\n",
    "#         b4=a.iloc[3]\n",
    "\n",
    "#         c1=str(b1).replace(\"[\", \"\")#strip('[]')\n",
    "#         d1=c1.replace(\"]\", \"\")\n",
    "#         c2=str(b2).replace(\"[\", \"\")#strip('[]')\n",
    "#         d2=c2.replace(\"]\", \"\")\n",
    "#         c3=str(b3).replace(\"[\", \"\")#strip('[]')\n",
    "#         d3=c3.replace(\"]\", \"\")\n",
    "#         c4=str(b4).replace(\"[\", \"\")#strip('[]')\n",
    "#         d4=c4.replace(\"]\", \"\")\n",
    "\n",
    "#         e1=Convert(d1)\n",
    "#         e2=Convert(d2)\n",
    "#         e3=Convert(d3)\n",
    "#         e4=Convert(d4)\n",
    "        \n",
    "#         e1=[float(i) for i in e1]\n",
    "#         e1=list(map(int,e1))\n",
    "#         e2=[float(i) for i in e2]\n",
    "#         e2=list(map(int,e2))\n",
    "#         e3=[float(i) for i in e3]\n",
    "#         e3=list(map(int,e3))\n",
    "#         e4=[float(i) for i in e4]\n",
    "#         e4=list(map(int,e4))\n",
    "\n",
    "#         x1= e1[::2]\n",
    "#         y1= e1[1::2] \n",
    "#         x2= e2[::2]\n",
    "#         y2= e2[1::2]\n",
    "#         x3= e3[::2]\n",
    "#         y3= e3[1::2]\n",
    "#         x4= e4[::2]\n",
    "#         y4= e4[1::2]\n",
    "\n",
    "#         base=filename+'.jpg'\n",
    "#         dict1 = {'filename': base,'regions': [{'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x1)),\n",
    "#                                              'all_points_y': list(map(int, y1))},'region_attributes': {'name': cat_name_1}},\n",
    "                                                \n",
    "#                                               {'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x2)),\n",
    "#                                              'all_points_y': list(map(int, y2))},'region_attributes': {'name': cat_name_2}},\n",
    "                                             \n",
    "#                                               {'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x3)),\n",
    "#                                             'all_points_y': list(map(int, y3))},'region_attributes': {'name': cat_name_3}},\n",
    "                                              \n",
    "#                                              {'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x4)),\n",
    "#                                             'all_points_y': list(map(int, y4))},'region_attributes': {'name': cat_name_4}}]}\n",
    "\n",
    "#         with open(filename+'_new.json', 'w') as fp:\n",
    "#             json.dump(dict1, fp)\n",
    "\n",
    "#     else:\n",
    "#         print(\"There are\",n,\"categories. Include more.\");\n",
    "#         break;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f95014522cf5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# switch between train and val as needed-----------------------------------------------------------------------here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'D:\\DCU\\Practicum\\Datasets\\DeepFashion2\\Mask RCNN\\Clothes\\Dataset_generator\\dataset\\train\\*.jpg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0msrc2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;31m#Select the last 10 characters(image name)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\glob.py\u001b[0m in \u001b[0;36m_iglob\u001b[1;34m(pathname, recursive, dironly)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdirname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob_in_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;31m# These 2 helper functions non-recursively glob inside a literal directory.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\ntpath.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(path, *paths)\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mresult_drive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplitdrive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m             \u001b[0mp_drive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplitdrive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mp_path\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mp_path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mseps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[1;31m# Second path is absolute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\ntpath.py\u001b[0m in \u001b[0;36msplitdrive\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;31m# colon) and the path specification.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;31m# It is always true that drivespec + pathspec == p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0msplitdrive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m     \"\"\"Split a pathname into drive/UNC sharepoint and relative path specifiers.\n\u001b[0;32m    124\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtuple\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdrive_or_unc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0meither\u001b[0m \u001b[0mpart\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mempty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Recursively going through all the files\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "def Convert(string): \n",
    "    li = list(string.split(\",\")) \n",
    "    return li\n",
    "\n",
    "# switch between train and val as needed-----------------------------------------------------------------------here\n",
    "for filepath in glob.iglob(r'D:\\DCU\\Practicum\\Datasets\\DeepFashion2\\Mask RCNN\\Clothes\\Dataset_generator\\dataset\\train\\annotations\\*.json', recursive=True):\n",
    "    \n",
    "    src1=filepath[-11:]#Select the last 11 characters\n",
    "    sep = '.'\n",
    "    filename = src1.split(sep, 1)[0]\n",
    "    #print(filename)\n",
    "    \n",
    "    df1=pd.read_json(filepath)\n",
    "    \n",
    "# switch between train and val as needed-----------------------------------------------------------------------here    \n",
    "    for filepath in glob.iglob(r'D:\\DCU\\Practicum\\Datasets\\DeepFashion2\\Mask RCNN\\Clothes\\Dataset_generator\\dataset\\train\\*.jpg', recursive=True):\n",
    "        src2=filepath[-10:]#Select the last 10 characters(image name)\n",
    "        sep = '.'\n",
    "        filename1 = src2.split(sep, 1)[0]\n",
    "        if(filename==filename1):\n",
    "                     \n",
    "            im = cv2.imread(filepath)\n",
    "            h, w, c = im.shape\n",
    "            #print('width:  ', w)\n",
    "            #print('height: ', h)\n",
    "       \n",
    "    \n",
    "    df1 = df1.loc[ ['category_name','segmentation'],:]\n",
    "    #Filter out all the unwanted columns and keep only those columns which have the necessary clothing item segment values and the \n",
    "    #category names.\n",
    "    df=df1.filter(like='item')\n",
    "    n=len(df.columns) \n",
    "    if n==1:\n",
    "        cat_name_1=df.iloc[0].iloc[0] #1st category\n",
    "        #print(\"Category1:\",cat_name_1)\n",
    "        a1=df.iloc[1]\n",
    "        \n",
    "        b1=a1.iloc[0]\n",
    "        \n",
    "        c1=str(b1).replace(\"[\", \"\")#strip('[]')\n",
    "        \n",
    "        d1=c1.replace(\"]\", \"\")\n",
    "        \n",
    "        e1=Convert(d1)\n",
    "        e1=[float(i) for i in e1]\n",
    "        e1=list(map(int,e1))\n",
    "        \n",
    "        x1= e1[::2] #numbers in even position\n",
    "        y1= e1[1::2] #numbers in odd position\n",
    "        \n",
    "        x1 = [w-1 if i>=w else i for i in x1]\n",
    "        y1 = [h-1 if i>=h else i for i in y1]\n",
    "        \n",
    "        base=filename+'.jpg'\n",
    "        dict1 =  {'filename': base,'regions': [{'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x1)),\n",
    "                                             'all_points_y': list(map(int, y1))},'region_attributes': {'name': cat_name_1}}]}\n",
    "        with open(filename+'_new.json', 'w') as fp:\n",
    "            json.dump(dict1, fp)\n",
    "\n",
    "\n",
    "    elif n==2:\n",
    "        cat_name_1=df.iloc[0].iloc[0]#1st category\n",
    "        cat_name_2=df.iloc[0].iloc[1]#2nd category\n",
    "        #print(\"Category1:\",cat_name_1,\"\\nCategory2:\",cat_name_2)\n",
    "        a=df.iloc[1]\n",
    "\n",
    "        b1=a.iloc[0]\n",
    "        b2=a.iloc[1]\n",
    "\n",
    "        c1=str(b1).replace(\"[\", \"\")#strip('[]')\n",
    "        d1=c1.replace(\"]\", \"\")\n",
    "        c2=str(b2).replace(\"[\", \"\")#strip('[]')\n",
    "        d2=c2.replace(\"]\", \"\")\n",
    "\n",
    "        e1=Convert(d1)\n",
    "        e2=Convert(d2)\n",
    "        \n",
    "        e1=[float(i) for i in e1]\n",
    "        e1=list(map(int,e1))\n",
    "        e2=[float(i) for i in e2]\n",
    "        e2=list(map(int,e2))\n",
    "\n",
    "        x1= e1[::2]\n",
    "        y1= e1[1::2] \n",
    "        x2= e2[::2]\n",
    "        y2= e2[1::2]\n",
    "        x1 = [w-1 if i>=w else i for i in x1]\n",
    "        y1 = [h-1 if i>=h else i for i in y1]\n",
    "        x2 = [w-1 if i>=w else i for i in x2]\n",
    "        y2 = [h-1 if i>=h else i for i in y2]\n",
    "\n",
    "        base=filename+'.jpg'\n",
    "        dict1 = {'filename': base,'regions': [{'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x1)),\n",
    "                                             'all_points_y': list(map(int, y1))},'region_attributes': {'name': cat_name_1}},\n",
    "                                                {'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x2)),\n",
    "                                             'all_points_y': list(map(int, y2))},'region_attributes': {'name': cat_name_2}}]}\n",
    "\n",
    "        with open(filename+'_new.json', 'w') as fp:\n",
    "            json.dump(dict1, fp)\n",
    "            \n",
    "    elif n==3:\n",
    "        cat_name_1=df.iloc[0].iloc[0]#1st category\n",
    "        cat_name_2=df.iloc[0].iloc[1]#2nd category\n",
    "        cat_name_3=df.iloc[0].iloc[2]#3nd category\n",
    "        #print(\"Category1:\",cat_name_1,\"\\nCategory2:\",cat_name_2)\n",
    "        a=df.iloc[1]\n",
    "\n",
    "        b1=a.iloc[0]\n",
    "        b2=a.iloc[1]\n",
    "        b3=a.iloc[2]\n",
    "\n",
    "        c1=str(b1).replace(\"[\", \"\")#strip('[]')\n",
    "        d1=c1.replace(\"]\", \"\")\n",
    "        c2=str(b2).replace(\"[\", \"\")#strip('[]')\n",
    "        d2=c2.replace(\"]\", \"\")\n",
    "        c3=str(b3).replace(\"[\", \"\")#strip('[]')\n",
    "        d3=c3.replace(\"]\", \"\")\n",
    "\n",
    "        e1=Convert(d1)\n",
    "        e2=Convert(d2)\n",
    "        e3=Convert(d3)\n",
    "        \n",
    "        e1=[float(i) for i in e1]\n",
    "        e1=list(map(int,e1))\n",
    "        e2=[float(i) for i in e2]\n",
    "        e2=list(map(int,e2))\n",
    "        e3=[float(i) for i in e3]\n",
    "        e3=list(map(int,e3))\n",
    "\n",
    "        x1= e1[::2]\n",
    "        y1= e1[1::2] \n",
    "        x2= e2[::2]\n",
    "        y2= e2[1::2]\n",
    "        x3= e3[::2]\n",
    "        y3= e3[1::2]\n",
    "        \n",
    "        x1 = [w-1 if i>=w else i for i in x1]\n",
    "        y1 = [h-1 if i>=h else i for i in y1]\n",
    "        x2 = [w-1 if i>=w else i for i in x2]\n",
    "        y2 = [h-1 if i>=h else i for i in y2]\n",
    "        x3 = [w-1 if i>=w else i for i in x3]\n",
    "        y3 = [h-1 if i>=h else i for i in y3]\n",
    "\n",
    "        base=filename+'.jpg'\n",
    "        dict1 = {'filename': base,'regions': [{'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x1)),\n",
    "                                             'all_points_y': list(map(int, y1))},'region_attributes': {'name': cat_name_1}},\n",
    "                                                \n",
    "                                              {'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x2)),\n",
    "                                             'all_points_y': list(map(int, y2))},'region_attributes': {'name': cat_name_2}},\n",
    "                                             \n",
    "                                              {'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x3)),\n",
    "                                            'all_points_y': list(map(int, y3))},'region_attributes': {'name': cat_name_3}}]}\n",
    "\n",
    "        with open(filename+'_new.json', 'w') as fp:\n",
    "            json.dump(dict1, fp)\n",
    "            \n",
    "    elif n==4:\n",
    "        cat_name_1=df.iloc[0].iloc[0]#1st category\n",
    "        cat_name_2=df.iloc[0].iloc[1]#2nd category\n",
    "        cat_name_3=df.iloc[0].iloc[2]#3nd category\n",
    "        cat_name_4=df.iloc[0].iloc[3]#3nd category\n",
    "        #print(\"Category1:\",cat_name_1,\"\\nCategory2:\",cat_name_2)\n",
    "        a=df.iloc[1]\n",
    "\n",
    "        b1=a.iloc[0]\n",
    "        b2=a.iloc[1]\n",
    "        b3=a.iloc[2]\n",
    "        b4=a.iloc[3]\n",
    "\n",
    "        c1=str(b1).replace(\"[\", \"\")#strip('[]')\n",
    "        d1=c1.replace(\"]\", \"\")\n",
    "        c2=str(b2).replace(\"[\", \"\")#strip('[]')\n",
    "        d2=c2.replace(\"]\", \"\")\n",
    "        c3=str(b3).replace(\"[\", \"\")#strip('[]')\n",
    "        d3=c3.replace(\"]\", \"\")\n",
    "        c4=str(b4).replace(\"[\", \"\")#strip('[]')\n",
    "        d4=c4.replace(\"]\", \"\")\n",
    "\n",
    "        e1=Convert(d1)\n",
    "        e2=Convert(d2)\n",
    "        e3=Convert(d3)\n",
    "        e4=Convert(d4)\n",
    "        \n",
    "        e1=[float(i) for i in e1]\n",
    "        e1=list(map(int,e1))\n",
    "        e2=[float(i) for i in e2]\n",
    "        e2=list(map(int,e2))\n",
    "        e3=[float(i) for i in e3]\n",
    "        e3=list(map(int,e3))\n",
    "        e4=[float(i) for i in e4]\n",
    "        e4=list(map(int,e4))\n",
    "\n",
    "        x1= e1[::2]\n",
    "        y1= e1[1::2] \n",
    "        x2= e2[::2]\n",
    "        y2= e2[1::2]\n",
    "        x3= e3[::2]\n",
    "        y3= e3[1::2]\n",
    "        x4= e4[::2]\n",
    "        y4= e4[1::2]\n",
    "        \n",
    "        x1 = [w-1 if i>=w else i for i in x1]\n",
    "        y1 = [h-1 if i>=h else i for i in y1]\n",
    "        x2 = [w-1 if i>=w else i for i in x2]\n",
    "        y2 = [h-1 if i>=h else i for i in y2]\n",
    "        x3 = [w-1 if i>=w else i for i in x3]\n",
    "        y3 = [h-1 if i>=h else i for i in y3]\n",
    "        x4 = [w-1 if i>=w else i for i in x4]\n",
    "        y4 = [h-1 if i>=h else i for i in y4]\n",
    "\n",
    "        base=filename+'.jpg'\n",
    "        dict1 = {'filename': base,'regions': [{'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x1)),\n",
    "                                             'all_points_y': list(map(int, y1))},'region_attributes': {'name': cat_name_1}},\n",
    "                                                \n",
    "                                              {'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x2)),\n",
    "                                             'all_points_y': list(map(int, y2))},'region_attributes': {'name': cat_name_2}},\n",
    "                                             \n",
    "                                              {'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x3)),\n",
    "                                            'all_points_y': list(map(int, y3))},'region_attributes': {'name': cat_name_3}},\n",
    "                                              \n",
    "                                             {'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x4)),\n",
    "                                            'all_points_y': list(map(int, y4))},'region_attributes': {'name': cat_name_4}}]}\n",
    "\n",
    "        with open(filename+'_new.json', 'w') as fp:\n",
    "            json.dump(dict1, fp)\n",
    "            \n",
    "    elif n==5:\n",
    "        cat_name_1=df.iloc[0].iloc[0]#1st category\n",
    "        cat_name_2=df.iloc[0].iloc[1]#2nd category\n",
    "        cat_name_3=df.iloc[0].iloc[2]#3nd category\n",
    "        cat_name_4=df.iloc[0].iloc[3]#3nd category\n",
    "        cat_name_5=df.iloc[0].iloc[4]#3nd category\n",
    "        #print(\"Category1:\",cat_name_1,\"\\nCategory2:\",cat_name_2)\n",
    "        a=df.iloc[1]\n",
    "\n",
    "        b1=a.iloc[0]\n",
    "        b2=a.iloc[1]\n",
    "        b3=a.iloc[2]\n",
    "        b4=a.iloc[3]\n",
    "        b5=a.iloc[4]\n",
    "\n",
    "        c1=str(b1).replace(\"[\", \"\")#strip('[]')\n",
    "        d1=c1.replace(\"]\", \"\")\n",
    "        c2=str(b2).replace(\"[\", \"\")#strip('[]')\n",
    "        d2=c2.replace(\"]\", \"\")\n",
    "        c3=str(b3).replace(\"[\", \"\")#strip('[]')\n",
    "        d3=c3.replace(\"]\", \"\")\n",
    "        c4=str(b4).replace(\"[\", \"\")#strip('[]')\n",
    "        d4=c4.replace(\"]\", \"\")\n",
    "        c5=str(b5).replace(\"[\", \"\")#strip('[]')\n",
    "        d5=c5.replace(\"]\", \"\")\n",
    "\n",
    "        e1=Convert(d1)\n",
    "        e2=Convert(d2)\n",
    "        e3=Convert(d3)\n",
    "        e4=Convert(d4)\n",
    "        e5=Convert(d5)\n",
    "        \n",
    "        e1=[float(i) for i in e1]\n",
    "        e1=list(map(int,e1))\n",
    "        e2=[float(i) for i in e2]\n",
    "        e2=list(map(int,e2))\n",
    "        e3=[float(i) for i in e3]\n",
    "        e3=list(map(int,e3))\n",
    "        e4=[float(i) for i in e4]\n",
    "        e4=list(map(int,e4))\n",
    "        e5=[float(i) for i in e5]\n",
    "        e5=list(map(int,e5))\n",
    "\n",
    "        x1= e1[::2]\n",
    "        y1= e1[1::2] \n",
    "        x2= e2[::2]\n",
    "        y2= e2[1::2]\n",
    "        x3= e3[::2]\n",
    "        y3= e3[1::2]\n",
    "        x4= e4[::2]\n",
    "        y4= e4[1::2]\n",
    "        x5= e5[::2]\n",
    "        y5= e5[1::2]\n",
    "        \n",
    "        x1 = [w-1 if i>=w else i for i in x1]\n",
    "        y1 = [h-1 if i>=h else i for i in y1]\n",
    "        x2 = [w-1 if i>=w else i for i in x2]\n",
    "        y2 = [h-1 if i>=h else i for i in y2]\n",
    "        x3 = [w-1 if i>=w else i for i in x3]\n",
    "        y3 = [h-1 if i>=h else i for i in y3]\n",
    "        x4 = [w-1 if i>=w else i for i in x4]\n",
    "        y4 = [h-1 if i>=h else i for i in y4]\n",
    "        x5 = [w-1 if i>=w else i for i in x5]\n",
    "        y5 = [h-1 if i>=h else i for i in y5]\n",
    "\n",
    "        base=filename+'.jpg'\n",
    "        dict1 = {'filename': base,'regions': [{'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x1)),\n",
    "                                             'all_points_y': list(map(int, y1))},'region_attributes': {'name': cat_name_1}},\n",
    "                                                \n",
    "                                              {'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x2)),\n",
    "                                             'all_points_y': list(map(int, y2))},'region_attributes': {'name': cat_name_2}},\n",
    "                                             \n",
    "                                              {'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x3)),\n",
    "                                            'all_points_y': list(map(int, y3))},'region_attributes': {'name': cat_name_3}},\n",
    "                                              \n",
    "                                             {'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x4)),\n",
    "                                            'all_points_y': list(map(int, y4))},'region_attributes': {'name': cat_name_4}},\n",
    "                                             \n",
    "                                             {'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x5)),\n",
    "                                            'all_points_y': list(map(int, y5))},'region_attributes': {'name': cat_name_5}}]}\n",
    "\n",
    "        with open(filename+'_new.json', 'w') as fp:\n",
    "            json.dump(dict1, fp)\n",
    "            \n",
    "    elif n==6:\n",
    "        cat_name_1=df.iloc[0].iloc[0]#1st category\n",
    "        cat_name_2=df.iloc[0].iloc[1]#2nd category\n",
    "        cat_name_3=df.iloc[0].iloc[2]#3nd category\n",
    "        cat_name_4=df.iloc[0].iloc[3]#3nd category\n",
    "        cat_name_5=df.iloc[0].iloc[4]#3nd category\n",
    "        cat_name_6=df.iloc[0].iloc[5]#3nd category\n",
    "        #print(\"Category1:\",cat_name_1,\"\\nCategory2:\",cat_name_2)\n",
    "        a=df.iloc[1]\n",
    "\n",
    "        b1=a.iloc[0]\n",
    "        b2=a.iloc[1]\n",
    "        b3=a.iloc[2]\n",
    "        b4=a.iloc[3]\n",
    "        b5=a.iloc[4]\n",
    "        b6=a.iloc[5]\n",
    "\n",
    "        c1=str(b1).replace(\"[\", \"\")#strip('[]')\n",
    "        d1=c1.replace(\"]\", \"\")\n",
    "        c2=str(b2).replace(\"[\", \"\")#strip('[]')\n",
    "        d2=c2.replace(\"]\", \"\")\n",
    "        c3=str(b3).replace(\"[\", \"\")#strip('[]')\n",
    "        d3=c3.replace(\"]\", \"\")\n",
    "        c4=str(b4).replace(\"[\", \"\")#strip('[]')\n",
    "        d4=c4.replace(\"]\", \"\")\n",
    "        c5=str(b5).replace(\"[\", \"\")#strip('[]')\n",
    "        d5=c5.replace(\"]\", \"\")\n",
    "        c6=str(b6).replace(\"[\", \"\")#strip('[]')\n",
    "        d6=c6.replace(\"]\", \"\")\n",
    "\n",
    "        e1=Convert(d1)\n",
    "        e2=Convert(d2)\n",
    "        e3=Convert(d3)\n",
    "        e4=Convert(d4)\n",
    "        e5=Convert(d5)\n",
    "        e6=Convert(d6)\n",
    "        \n",
    "        e1=[float(i) for i in e1]\n",
    "        e1=list(map(int,e1))\n",
    "        e2=[float(i) for i in e2]\n",
    "        e2=list(map(int,e2))\n",
    "        e3=[float(i) for i in e3]\n",
    "        e3=list(map(int,e3))\n",
    "        e4=[float(i) for i in e4]\n",
    "        e4=list(map(int,e4))\n",
    "        e5=[float(i) for i in e5]\n",
    "        e5=list(map(int,e5))\n",
    "        e6=[float(i) for i in e6]\n",
    "        e6=list(map(int,e6))\n",
    "\n",
    "        x1= e1[::2]\n",
    "        y1= e1[1::2] \n",
    "        x2= e2[::2]\n",
    "        y2= e2[1::2]\n",
    "        x3= e3[::2]\n",
    "        y3= e3[1::2]\n",
    "        x4= e4[::2]\n",
    "        y4= e4[1::2]\n",
    "        x5= e5[::2]\n",
    "        y5= e5[1::2]\n",
    "        x6= e6[::2]\n",
    "        y6= e6[1::2]\n",
    "        \n",
    "        x1 = [w-1 if i>=w else i for i in x1]\n",
    "        y1 = [h-1 if i>=h else i for i in y1]\n",
    "        x2 = [w-1 if i>=w else i for i in x2]\n",
    "        y2 = [h-1 if i>=h else i for i in y2]\n",
    "        x3 = [w-1 if i>=w else i for i in x3]\n",
    "        y3 = [h-1 if i>=h else i for i in y3]\n",
    "        x4 = [w-1 if i>=w else i for i in x4]\n",
    "        y4 = [h-1 if i>=h else i for i in y4]\n",
    "        x5 = [w-1 if i>=w else i for i in x5]\n",
    "        y5 = [h-1 if i>=h else i for i in y5]\n",
    "        x6 = [w-1 if i>=w else i for i in x6]\n",
    "        y6 = [h-1 if i>=h else i for i in y6]\n",
    "\n",
    "        base=filename+'.jpg'\n",
    "        dict1 = {'filename': base,'regions': [{'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x1)),\n",
    "                                             'all_points_y': list(map(int, y1))},'region_attributes': {'name': cat_name_1}},\n",
    "                                                \n",
    "                                              {'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x2)),\n",
    "                                             'all_points_y': list(map(int, y2))},'region_attributes': {'name': cat_name_2}},\n",
    "                                             \n",
    "                                              {'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x3)),\n",
    "                                            'all_points_y': list(map(int, y3))},'region_attributes': {'name': cat_name_3}},\n",
    "                                              \n",
    "                                             {'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x4)),\n",
    "                                            'all_points_y': list(map(int, y4))},'region_attributes': {'name': cat_name_4}},\n",
    "                                             \n",
    "                                             {'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x5)),\n",
    "                                            'all_points_y': list(map(int, y5))},'region_attributes': {'name': cat_name_5}},\n",
    "                                             \n",
    "                                             {'shape_attributes': {'name': 'polygon','all_points_x': list(map(int, x6)),\n",
    "                                            'all_points_y': list(map(int, y6))},'region_attributes': {'name': cat_name_6}}]}\n",
    "\n",
    "        with open(filename+'_new.json', 'w') as fp:\n",
    "            json.dump(dict1, fp)\n",
    "\n",
    "    else:\n",
    "        print(\"There are\",n,\"categories. Include more.\");\n",
    "        break;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging all the jsons into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\DCU\\\\Practicum\\\\Datasets\\\\DeepFashion2\\\\Mask RCNN\\\\Clothes\\\\Dataset_generator\\\\dataset\\\\val\\\\annotations\\\\new_annotations'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "read_files = glob.glob(\"*.json\")\n",
    "with open(\"via_region_data.json\", \"w\") as outfile:\n",
    "    outfile.write('[{}]'.format(','.join([open(f, \"r\").read() for f in read_files])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('via_region_data.json') as data_file:\n",
    "    test = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-86a6e14c5112>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shap'"
     ]
    }
   ],
   "source": [
    "test.shap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the following if need be only\n",
    "This is to check the working with clothes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\DCU\\\\Practicum\\\\Datasets\\\\DeepFashion2\\\\Mask RCNN\\\\Clothes\\\\Dataset_generator\\\\dataset\\\\val\\\\annotations\\\\new_annotations'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objects: ['short sleeve top', 'trousers']\n",
      "objects: ['shorts', 'vest']\n",
      "objects: ['short sleeve dress']\n",
      "objects: ['trousers', 'long sleeve dress']\n",
      "objects: ['sling dress']\n"
     ]
    }
   ],
   "source": [
    "annotations = json.load(open(\"via_region_data.json\"))\n",
    "# print(annotations1)\n",
    "#annotations = list(annotations1)  # don't need the dict keys\n",
    "\n",
    "# The VIA tool saves images in the JSON even if they don't have any\n",
    "# annotations. Skip unannotated images.\n",
    "annotations = [a for a in annotations if a['regions']]\n",
    "\n",
    "# Add images\n",
    "for a in annotations:\n",
    "    # print(a)\n",
    "    # Get the x, y coordinaets of points of the polygons that make up\n",
    "    # the outline of each object instance. There are stores in the\n",
    "    # shape_attributes (see json format above)\n",
    "    polygons = [r['shape_attributes'] for r in a['regions']] \n",
    "    objects = [s['region_attributes']['name'] for s in a['regions']]\n",
    "    print(\"objects:\",objects)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
